{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###1.Set up enviroment"
      ],
      "metadata": {
        "id": "J_YzpukQ6x0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Install packages"
      ],
      "metadata": {
        "id": "nOqKOV8b66OI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M36kVbWVuvYK",
        "outputId": "12316c34-46ae-41e5-a3f0-5e09e6988c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting orjson==3.9.14\n",
            "  Downloading orjson-3.9.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.9.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/139.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: orjson\n",
            "Successfully installed orjson-3.9.14\n",
            "Collecting pdfplumber==0.9.0\n",
            "  Downloading pdfplumber-0.9.0-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting pdfminer.six==20221105 (from pdfplumber==0.9.0)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber==0.9.0) (9.4.0)\n",
            "Collecting Wand>=0.6.10 (from pdfplumber==0.9.0)\n",
            "  Downloading Wand-0.6.13-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber==0.9.0) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber==0.9.0) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber==0.9.0) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber==0.9.0) (2.22)\n",
            "Downloading pdfplumber-0.9.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Wand-0.6.13-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Wand, pdfminer.six, pdfplumber\n",
            "Successfully installed Wand-0.6.13 pdfminer.six-20221105 pdfplumber-0.9.0\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n",
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n",
            "Collecting ollama\n",
            "  Downloading ollama-0.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama) (0.27.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n",
            "Downloading ollama-0.3.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: ollama\n",
            "Successfully installed ollama-0.3.1\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.7.4)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_inference-1.0.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.0.3-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client\n",
            "Successfully installed pinecone-client-5.0.1 pinecone-plugin-inference-1.0.3 pinecone-plugin-interface-0.0.7\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.27 (from langchain)\n",
            "  Downloading langchain_core-0.2.29-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.98-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.14)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.29-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.98-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.12 langchain-core-0.2.29 langchain-text-splitters-0.2.2 langsmith-0.1.98 tenacity-8.5.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.12)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.29)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.98)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.9.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.11 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.5 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (3.10.1)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.2.29)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.26.4)\n",
            "Requirement already satisfied: pinecone-client<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (5.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.5->langchain_pinecone) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.5->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.5->langchain_pinecone) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.5->langchain_pinecone) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.5->langchain_pinecone) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.5->langchain_pinecone) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.5->langchain_pinecone) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (0.1.98)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2024.7.4)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (1.0.3)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (4.66.5)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.0.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.9.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.9.5->langchain_pinecone) (3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.3.2)\n",
            "Downloading langchain_pinecone-0.1.3-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: langchain_pinecone\n",
            "Successfully installed langchain_pinecone-0.1.3\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.1.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.9.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.2.29)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (0.1.98)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (8.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.9.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.0.7)\n",
            "Downloading langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: langchain_groq\n",
            "Successfully installed langchain_groq-0.1.9\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting PyMuPDFb==1.24.9 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.24.9 pymupdf-1.24.9\n",
            "Collecting colab-xterm\n",
            "  Downloading colab_xterm-0.2.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: ptyprocess~=0.7.0 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (0.7.0)\n",
            "Requirement already satisfied: tornado>5.1 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (6.3.3)\n",
            "Downloading colab_xterm-0.2.0-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: colab-xterm\n",
            "Successfully installed colab-xterm-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install orjson==3.9.14\n",
        "!pip install pdfplumber==0.9.0\n",
        "!pip install unidecode\n",
        "!pip install groq\n",
        "!pip install ollama\n",
        "!pip install pinecone-client\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langchain_pinecone\n",
        "!pip install langchain_groq\n",
        "!pip install python-dotenv\n",
        "!pip install pymupdf\n",
        "!pip install colab-xterm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Connect servers\n"
      ],
      "metadata": {
        "id": "ynEJn39Z7Dnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up ollama server\n",
        "%load_ext colabxterm\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!ollama serve > ollama.log 2>&1 &\n",
        "!ollama pull nomic-embed-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGmq6izn7VOG",
        "outputId": "f6cf104a-bd94-40da-f754-dc09b980926d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The colabxterm extension is already loaded. To reload it, use:\n",
            "  %reload_ext colabxterm\n",
            ">>> Downloading ollama...\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 970aa74c0a90... 100% ▕▏ 274 MB                         \n",
            "pulling c71d239df917... 100% ▕▏  11 KB                         \n",
            "pulling ce4a164fc046... 100% ▕▏   17 B                         \n",
            "pulling 31df23ea7daa... 100% ▕▏  420 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 970aa74c0a90... 100% ▕▏ 274 MB                         \n",
            "pulling c71d239df917... 100% ▕▏  11 KB                         \n",
            "pulling ce4a164fc046... 100% ▕▏   17 B                         \n",
            "pulling 31df23ea7daa... 100% ▕▏  420 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 970aa74c0a90... 100% ▕▏ 274 MB                         \n",
            "pulling c71d239df917... 100% ▕▏  11 KB                         \n",
            "pulling ce4a164fc046... 100% ▕▏   17 B                         \n",
            "pulling 31df23ea7daa... 100% ▕▏  420 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 970aa74c0a90... 100% ▕▏ 274 MB                         \n",
            "pulling c71d239df917... 100% ▕▏  11 KB                         \n",
            "pulling ce4a164fc046... 100% ▕▏   17 B                         \n",
            "pulling 31df23ea7daa... 100% ▕▏  420 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 970aa74c0a90... 100% ▕▏ 274 MB                         \n",
            "pulling c71d239df917... 100% ▕▏  11 KB                         \n",
            "pulling ce4a164fc046... 100% ▕▏   17 B                         \n",
            "pulling 31df23ea7daa... 100% ▕▏  420 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "removing any unused layers \n",
            "success \u001b[?25h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.Import required tools"
      ],
      "metadata": {
        "id": "Hpb2dIvG7IQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Warnings"
      ],
      "metadata": {
        "id": "0I4kZClqsP07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "mpGm7CSesOE0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tools"
      ],
      "metadata": {
        "id": "0CrzOanZp6sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_groq import ChatGroq\n",
        "from unidecode import unidecode\n",
        "from langchain.schema import SystemMessage\n",
        "from pinecone import Pinecone\n",
        "from pinecone import Vector\n",
        "from tqdm import tqdm\n",
        "import pdfplumber\n",
        "import os"
      ],
      "metadata": {
        "id": "6FtZzEIXxf4d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.Set up API Keys"
      ],
      "metadata": {
        "id": "ywrKMe6Bp4SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define up required API Keys\n",
        "os.environ[\"GROQ_API_KEY\"] = \"<Insert you groq api key here>\"\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"<Insert you pinecone api key here>\"\n",
        "\n",
        "# Set up required API Keys\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
      ],
      "metadata": {
        "id": "Fs5ZETMMUkuY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.Create database"
      ],
      "metadata": {
        "id": "e2ZnoTrD7ucL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Utilities"
      ],
      "metadata": {
        "id": "zOVQDWizDibs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load pdf documents\n",
        "def load_document(docs_dir, doc_name):\n",
        "  # create a document path\n",
        "  doc_path = os.path.join(docs_dir, doc_name)\n",
        "  # load pdf file and extract text\n",
        "  document = []\n",
        "  with pdfplumber.open(doc_path) as pdf:\n",
        "      for page in pdf.pages:\n",
        "          document.append(page.extract_text())\n",
        "  # join all pages' text into a single string\n",
        "  text = \"\\n\".join(document)\n",
        "  return text\n",
        "\n",
        "\n",
        "# Function to chunk a document\n",
        "def split_document(text):\n",
        "  # define a splitter strategy\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "  # split the text document into chunks\n",
        "  chunks = text_splitter.split_text(text)\n",
        "  return chunks\n",
        "\n",
        "\n",
        "# Function to embed text from a document pre-chunked\n",
        "def embed_document(chunks):\n",
        "  # define an embedding model\n",
        "  embedding_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "  # embed the text\n",
        "  embeddings = embedding_model.embed_documents(chunks)\n",
        "  return embeddings\n",
        "\n",
        "\n",
        "# Function to create pinecone vectos\n",
        "def create_vectors(doc_name, chunks, embeddings):\n",
        "  # array to save vectors\n",
        "  vectors = []\n",
        "  # create a Vector instance\n",
        "  for i, chunk in enumerate(chunks):\n",
        "    vector_id = f\"{i}-{unidecode(doc_name)}\"\n",
        "    vector = Vector(\n",
        "        id=vector_id,\n",
        "        values=embeddings[i],\n",
        "        metadata={\"source\": unidecode(doc_name), \"text\": chunk}\n",
        "    )\n",
        "    # save vector\n",
        "    vectors.append(vector)\n",
        "  return vectors\n",
        "\n",
        "\n",
        "# Function to upser a document vectors into a pinecone DB\n",
        "def upsert_document(doc_name, vectors):\n",
        "  # connect to a pinecone DB\n",
        "  pinecone_client = Pinecone(apikey=PINECONE_API_KEY)\n",
        "  # get a pre-existed pinecone index\n",
        "  pinecone_index = pinecone_client.Index(name='test')\n",
        "  # define a batch size\n",
        "  batch_size = 1000\n",
        "  # define the total number of vectors\n",
        "  total_vectors = len(vectors)\n",
        "  # upsert all vectors\n",
        "  for i in tqdm(range(0, total_vectors, batch_size), desc=f\"Upserting {doc_name}\"):\n",
        "    batch = vectors[i:i+batch_size]\n",
        "    pinecone_index.upsert(\n",
        "        vectors=batch,\n",
        "        show_progress=False\n",
        "                  )\n",
        "  print(f'Document {doc_name} was succesfully loaded!')"
      ],
      "metadata": {
        "id": "eebqK34h7Zii"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Database"
      ],
      "metadata": {
        "id": "fxKttdkWDlVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process documents and uploading them into a DB\n",
        "def create_database(docs_dir):\n",
        "  # header\n",
        "  print(\" 🗃️Loading documents...\")\n",
        "  print('')\n",
        "  # get documents list of pdf documents\n",
        "  docs_names = [name for name in os.listdir(docs_dir) if name.lower().endswith('.pdf')]\n",
        "  # process all documents\n",
        "  for i, name in enumerate(docs_names):\n",
        "    # load document\n",
        "    text = load_document(docs_dir=docs_dir, doc_name=name)\n",
        "    # create chunks\n",
        "    chunks = split_document(text=text)\n",
        "    # convert chunks into embeddingss\n",
        "    embeddings = embed_document(chunks=chunks)\n",
        "    # create vectors instances\n",
        "    vectors = create_vectors(doc_name=name, chunks=chunks, embeddings=embeddings)\n",
        "    # upload documentos into a pinecone DB\n",
        "    upsert_document(doc_name=name, vectors=vectors)\n",
        "  # footer\n",
        "  print('')\n",
        "  print(\"Your documents were succesfully loaded!\")\n",
        "  print('')\n"
      ],
      "metadata": {
        "id": "QqoZTbcReHH1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.Create chatbot"
      ],
      "metadata": {
        "id": "cQ9f0vlcDSRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Utils\n"
      ],
      "metadata": {
        "id": "DExSE6gqPzD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load a LLM\n",
        "def load_llm():\n",
        "  # create llm instance\n",
        "  llm = ChatGroq(\n",
        "  groq_api_key=GROQ_API_KEY,\n",
        "  model_name='llama-3.1-8b-instant',\n",
        "  temperature=0.25,\n",
        "  max_tokens=1024\n",
        "  )\n",
        "  return llm\n",
        "\n",
        "\n",
        "# Function to create a vectorstore from a pinecone DB\n",
        "def create_vectorstore():\n",
        "  # connect to a pinecone DB\n",
        "  pinecone_client = Pinecone(apikey=PINECONE_API_KEY)\n",
        "  # get a pre-existed pinecone index\n",
        "  pinecone_index = pinecone_client.Index(name='test')\n",
        "  # define an embedding model\n",
        "  embedding_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "  # create a vectorstore\n",
        "  vectorstore = LangchainPinecone(pinecone_index, embedding_model.embed_query, \"text\")\n",
        "  return vectorstore\n",
        "\n",
        "\n",
        "# Function to create a memory instance\n",
        "def create_memory():\n",
        "  # configure memory object\n",
        "  memory = ConversationBufferMemory(memory_key=\"chat_history\", output_key='answer', return_messages=True)\n",
        "  return memory\n",
        "\n",
        "\n",
        "# Function to create a refined prompt\n",
        "def create_prompt(memory):\n",
        "  # define an initial system instruction\n",
        "  system_instruction = \"Your name is Boto and you are my personal AI assistant, you were created to help in anything. You always respond in English.\"\n",
        "  # create initial system message instance\n",
        "  initial_message = SystemMessage(content=system_instruction)\n",
        "  # add initial system message to memory\n",
        "  memory.chat_memory.add_message(initial_message)\n",
        "  # system prompt template\n",
        "  system_template = (\n",
        "    f\"{system_instruction}\\n\\n\"\n",
        "    \"Based on the following retrieved information, chat history, and user query, provide comprehensive and accurate responses.\"\n",
        "  )\n",
        "  # human prompt template\n",
        "  human_template = (\n",
        "    \"retrieved information: {context}\\n\"\n",
        "    \"chat history: {chat_history}\\n\"\n",
        "    \"user query: {question}\\n\"\n",
        "    \"Detailed answer:\"\n",
        "  )\n",
        "  # create system prompt instance\n",
        "  system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "  # create human prompt instance\n",
        "  human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "  # create convesation chain prompt\n",
        "  qa_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "  return qa_prompt\n",
        "\n",
        "\n",
        "def create_qa_chain(llm, vectorstore):\n",
        "  # initialize a memory\n",
        "  memory = create_memory()\n",
        "  # create a prompt\n",
        "  qa_prompt = create_prompt(memory=memory)\n",
        "  # create a qa conversation chain\n",
        "  qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "      llm=llm,\n",
        "      return_source_documents=True,\n",
        "      retriever=vectorstore.as_retriever(),\n",
        "      memory=memory,\n",
        "      verbose=False,\n",
        "      chain_type='stuff',\n",
        "      output_key='answer',\n",
        "      combine_docs_chain_kwargs={\"prompt\": qa_prompt}\n",
        "  )\n",
        "  return qa_chain\n",
        "\n",
        "\n",
        "# display chat header\n",
        "def header():\n",
        "  print('')\n",
        "  print('Hey! (Type \"exit\" to finish this conversation)')\n",
        "  print('')\n",
        "\n",
        "\n",
        "# user query\n",
        "def user_query():\n",
        "  query = input(\"😎You: \")\n",
        "  return query\n",
        "\n",
        "\n",
        "# exit message\n",
        "def exit_query(query):\n",
        "  if query.lower() == \"exit\":\n",
        "    print(\"See you soon!\")\n",
        "    print('')\n",
        "    return True\n",
        "\n",
        "\n",
        "# Function to handle queries\n",
        "def handle_query(query, qa_chain):\n",
        "  # get query result\n",
        "  result = qa_chain.invoke({\"question\": query})\n",
        "  # extract assistant answer\n",
        "  answer = result['answer']\n",
        "  # extract unique source documents names\n",
        "  src_documents = set([doc.metadata['source'].split('.')[0] for doc in result['source_documents']])\n",
        "  return answer, src_documents\n",
        "\n",
        "\n",
        "# get assistant answer\n",
        "def assistant_answer(answer, src_documents):\n",
        "  # display assistant answer\n",
        "  print(\"🤖 Assistant:\", answer)\n",
        "  # display source documents\n",
        "  print('')\n",
        "  print('Reference documents:')\n",
        "  for doc in src_documents:\n",
        "    print(doc)\n",
        "\n"
      ],
      "metadata": {
        "id": "KbEQMaGvB_yg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####chat"
      ],
      "metadata": {
        "id": "mOFFrIX_pYJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat():\n",
        "    # load a LLM (default:Llama 3.1)\n",
        "    llm = load_llm()\n",
        "    # initialize a vectorstore\n",
        "    vectorstore = create_vectorstore()\n",
        "    # initialize a QA chain\n",
        "    qa_chain = create_qa_chain(llm=llm, vectorstore=vectorstore)\n",
        "    # display chat header\n",
        "    header()\n",
        "    # conversation logic\n",
        "    while True:\n",
        "        # get user query\n",
        "        query = user_query()\n",
        "        # check if user wants to exit\n",
        "        if exit_query(query):\n",
        "            break\n",
        "        # get chat answer\n",
        "        answer, src_documents = handle_query(query=query, qa_chain=qa_chain)\n",
        "        # display bot answer\n",
        "        assistant_answer(answer=answer, src_documents=src_documents)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "Cy_-_6T7pb3w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6.App"
      ],
      "metadata": {
        "id": "mxPSaEQtxyvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Utils"
      ],
      "metadata": {
        "id": "aSxEbVLayDvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to give a welcome message\n",
        "def welcome():\n",
        "  # give an app welcome message\n",
        "  print(\"Welcome! my name is Boto, I am your virtual assistant🤖\")\n",
        "\n",
        "\n",
        "# Function to display an app menu\n",
        "def options():\n",
        "  # define app options\n",
        "  options = ['Load documents', 'Chat with Boto', 'Exit']\n",
        "  # display options\n",
        "  for number, option in enumerate(options, start=1):\n",
        "    print(f'{number}. {option}')\n",
        "  # app menu logic\n",
        "  while True:\n",
        "    # get uset option selection\n",
        "    answer = input('What would you like to do?')\n",
        "    # validate user option is a number within options menu\n",
        "    try:\n",
        "      answer = int(answer)\n",
        "      # verify user option is available\n",
        "      if answer == 1 or answer == 2 or answer == 3:\n",
        "        return answer\n",
        "      else:\n",
        "        print(\"Type (1) or (2) to select and option and (3) to exit\")\n",
        "    # catch error\n",
        "    except ValueError as e:\n",
        "      print(\"Type (1) or (2) to select and option and (3) to exit\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4RXPuyvfx1V6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####app"
      ],
      "metadata": {
        "id": "KxtVRV_kLmXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def app():\n",
        "    # welcome message\n",
        "    welcome()\n",
        "    # app menu manager logic\n",
        "    while True:\n",
        "        # display options menu\n",
        "        option = options()\n",
        "        if option == 1:\n",
        "          # define directory where documents are storaged\n",
        "          docs_dir = '/content/documents/'\n",
        "          # create pinecon db\n",
        "          create_database(docs_dir=docs_dir)\n",
        "        elif option == 2:\n",
        "          # chat with boto\n",
        "          chat()\n",
        "        else:\n",
        "          # exit\n",
        "          break"
      ],
      "metadata": {
        "id": "ce6rK4Z6ITEf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.Run app"
      ],
      "metadata": {
        "id": "TEwWul5LLt2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run Boto-AI assistant app\n",
        "app()"
      ],
      "metadata": {
        "id": "umpGhsiDLxkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579b926c-5311-4953-da8f-418260fd9e14"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! my name is Boto, I am your virtual assistant🤖\n",
            "1. Load documents\n",
            "2. Chat with Boto\n",
            "3. Exit\n",
            "What would you like to do?1\n",
            " 🗃️Loading documents...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Upserting cv_RigobertoRinconBallesteros.pdf: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document cv_RigobertoRinconBallesteros.pdf was succesfully loaded!\n",
            "\n",
            "Your documents were succesfully loaded!\n",
            "\n",
            "1. Load documents\n",
            "2. Chat with Boto\n",
            "3. Exit\n",
            "What would you like to do?2\n",
            "\n",
            "Hey! (Type \"exit\" to finish this conversation)\n",
            "\n",
            "😎You: Hello, how are you today?\n",
            "🤖 Assistant: Hello! I'm Boto, your personal AI assistant. I'm functioning within normal parameters and ready to assist you with any questions or tasks you may have. It's great to start our conversation today! How can I help you?\n",
            "\n",
            "Reference documents:\n",
            "cv_RigobertoRinconBallesteros\n",
            "\n",
            "😎You: do you know Rigoberto Rincón?\n",
            "🤖 Assistant: I have access to information about Rigoberto Rincón Ballesteros. According to the retrieved information, Rigoberto Rincón is a biochemical engineer with a strong background in quality control laboratories and biotechnological research. He has experience working in multidisciplinary teams and has skills in programming languages such as Python, Matlab, and SQL basics, as well as version control using Git and Git bash.\n",
            "\n",
            "Rigoberto is currently pursuing a Master's degree in Bioengineering and Intelligent Computing at the University of Guadalajara. He has also completed a research internship at the University of Minho in Portugal and worked as an Analytical Chemist at PiSA Laboratories.\n",
            "\n",
            "Additionally, Rigoberto has received an award for the Best Scientific Poster Presentation at the Bioinformatics Open Days 2024 international conference. His LinkedIn profile is also available, which can provide more information about his professional experience and skills.\n",
            "\n",
            "Overall, Rigoberto Rincón appears to be a highly skilled and accomplished biochemical engineer with a strong background in research and biotechnology.\n",
            "\n",
            "Reference documents:\n",
            "cv_RigobertoRinconBallesteros\n",
            "\n",
            "😎You: exit\n",
            "See you soon!\n",
            "\n",
            "1. Load documents\n",
            "2. Chat with Boto\n",
            "3. Exit\n",
            "What would you like to do?3\n"
          ]
        }
      ]
    }
  ]
}